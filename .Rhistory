for (i in 2:n_rows){
set.seed(321)
clust_kpp = kmeans(ALS_Data_Short_Scale, kpp_init(ALS_Data_Short_Scale, i), iter.max=100, algorithm='Lloyd')
sil = silhouette(clust_kpp$cluster, dist(ALS_Data_Short_Scale))
mat[i] = mean(as.matrix(sil)[,3])
}
colnames(mat) <- c("Avg_Silhouette_Value")
ggplot(data.frame(k=2:n_rows,sil=mat[2:n_rows]),aes(x=k,y=sil))+
geom_line()+
scale_x_continuous(breaks = 2:n_rows)
k <- 3
set.seed(2019)
clust_kpp = kmeans(ALS_Data_Short_Scale, kpp_init(ALS_Data_Short_Scale, k), iter.max=200, algorithm="MacQueen")
sil_kmean.opt = silhouette(clust_kpp$cluster, dist(ALS_Data_Short_Scale))
summary(sil_kmean.opt)
plot(sil_kmean.opt)
pitch_sing = agnes(ALS_Data_Short_Scale, diss=FALSE, method='single')
pitch_comp = agnes(ALS_Data_Short_Scale, diss=FALSE, method='complete')
pitch_ward = agnes(ALS_Data_Short_Scale, diss=FALSE, method='ward')
sil_sing = silhouette(cutree(pitch_sing, k=3), dist(ALS_Data_Short_Scale))
sil_comp = silhouette(cutree(pitch_comp, k=3), dist(ALS_Data_Short_Scale))
sil_ward = silhouette(cutree(pitch_ward, k=3), dist(ALS_Data_Short_Scale))
plot(sil_sing)
plot(sil_comp)
plot(sil_ward)
set.seed(2019)
gmm_clust <- Mclust(ALS_Data_Short_Scale)
gmm_clust$modelName
plot(gmm_clust$BIC, legendArgs = list(x = "bottom", ncol = 2, cex = 1))
mod <- Mclust(ALS_Data_Short_Scale[,1:6])
plot(mod, what = "density")
plot(mod, what = "classification")
sil_gauss = silhouette(as.numeric(gmm_clust$classification), dist(ALS_Data_Short_Scale))
plot(sil_gauss)
mean(sil_kmean[,3])
mean(sil_kmean.opt[,3])
mean(sil_sing[,3])
mean(sil_comp[,3])
mean(sil_ward[,3])
mean(sil_gauss[,3])
sil
lambda = 2 #input power value here
ifelse((lambda<0), (rand_data = abs(runif(2000, 1, 2))),
ifelse((lambda>0 & lambda<=1), (rand_data = abs(runif(2000, 0, 100))),
ifelse((lambda>1), (rand_data = runif(2000, -1,1)),
ifelse((lambda==0), (rand_data = sample(1:2000, 2000)),
(rand_data = 0)
))))
power_df <- data.frame(rand_data, power_data=round(rand_data^lambda,3))
ggplot(power_df, aes(rand_data,power_data, color=rand_data)) +
geom_point(show.legend = F) + scale_color_gradient(low="yellow", high="red") +
ggtitle(paste("Power of",lambda,"- function Plot")) + labs(x='x',y = bquote(x^~.(lambda))) + theme_dark()
library(tibble);library(kableExtra);library(rvest); library(mclust)
library(DT);library(GGally); library(ggplot2); library(neuralnet); library(matrixStats)
library(kernlab); library(gridExtra); library(stats); library(cluster); library(cluster)
lambda = 2 #input power value here
ifelse((lambda<0), (rand_data = abs(runif(2000, 1, 2))),
ifelse((lambda>0 & lambda<=1), (rand_data = abs(runif(2000, 0, 100))),
ifelse((lambda>1), (rand_data = runif(2000, -1,1)),
ifelse((lambda==0), (rand_data = sample(1:2000, 2000)),
(rand_data = 0)
))))
power_df <- data.frame(rand_data, power_data=round(rand_data^lambda,3))
ggplot(power_df, aes(rand_data,power_data, color=rand_data)) +
geom_point(show.legend = F) + scale_color_gradient(low="yellow", high="red") +
ggtitle(paste("Power of",lambda,"- function Plot")) + labs(x='x',y = bquote(x^~.(lambda))) + theme_dark()
set.seed(2019)
train_size <- floor(0.9*nrow(power_df))
trainid <- sample(seq_len(nrow(power_df)), size = train_size)
training <- power_df[trainid,]
ifelse(lambda>1, {a=-2 ; b=2.94775 ; c=0.00275},
ifelse((lambda>0 & lambda<=1),{a=0.1 ; b=180 ; c=0.1},
{a=2 ; b=3-(1/1800) ; c=1/1800}))
new_test <- data.frame(rand_data=seq(a, b, c))
new_test$power_data <- new_test$rand_data^lambda
new_test <- rbind(new_test, power_df[-trainid,])
set.seed(2019)
net.pwr <- neuralnet(power_data ~ rand_data, training, hidden=10, threshold = 0.1)
pred_power_nn <- predict(net.pwr, new_test)
results_nn <- data.frame(actual=new_test$power_data, prediction=pred_power_nn)
mse_nn <- mean((results_nn$actual-results_nn$prediction)^2)
svm.pwr <- ksvm(power_data ~ rand_data, data=training, kernel="polydot")
pred_power_svm <- predict(svm.pwr, new_test)
results_svm <- data.frame(actual=new_test$power_data, prediction=pred_power_svm)
mse_svm <- mean((results_svm$actual-results_svm$prediction)^2)
p1 <-
ggplot()+
geom_point(aes(new_test$rand_data, new_test$power_data, colour="Actual"))+
geom_line(aes(new_test$rand_data, pred_power_nn, colour="Predicted"), linetype="dashed")+
scale_color_manual(values = c(
'Actual' = 'firebrick',
'Predicted' = 'dodgerblue')) +
labs(colour=" ",x='x', y = bquote(x^~.(lambda)))+
ggtitle("Plot Actual Data vs Prediction of NN Model Results")+theme_light()
p2 <-
ggplot()+
geom_point(aes(new_test$rand_data, new_test$power_data, colour="Actual"))+
geom_line(aes(new_test$rand_data, pred_power_svm, colour="Predicted"), linetype="dashed")+
scale_color_manual(values = c(
'Actual' = 'firebrick',
'Predicted' = 'dodgerblue')) +
labs(colour=" ",x='x', y = bquote(x^~.(lambda)))+
ggtitle("Plot Actual Data vs Prediction of SVM Model Results")+theme_light()
grid.arrange(p1, p2, ncol=1)
ALS_Data <- as.data.frame(read.csv("https://umich.instructure.com/files/1789623/download?download_frd=1", header=T, na.strings=c("", ".", "NA", "NR")))
datatable(cbind(Min=lapply(ALS_Data, min), "1Q"=lapply(ALS_Data, quantile, probs=1/4), Mean=lapply(ALS_Data, mean), Median=lapply(ALS_Data, median), "3Q"=lapply(ALS_Data, quantile, probs=3/4), Max=lapply(ALS_Data, max)))
# Data visualization
par(mfrow=c(1,2))
hist(ALS_Data$Age_mean, main = "Histogram of Age Mean", xlab = "Mean of Age")
boxplot(ALS_Data$Hemoglobin_median~ALS_Data$Gender_mean,
main = "Hemoglobin Median vs Gender",
xlab = "Gender", ylab = "Median of Hemoglobin")
density_data.ALS <- subset(ALS_Data, select = c("Gender_mean", "pulse_median",
"Chloride_median","Calcium_median",
"Sodium_median"))
density_data.ALS$Gender_mean <- as.factor(density_data.ALS$Gender_mean)
p1 <- ggplot(density_data.ALS, aes(x=pulse_median, group = Gender_mean)) +
geom_density(aes(fill=Gender_mean), alpha=0.3)
p2 <- ggplot(density_data.ALS, aes(x=Chloride_median, group = Gender_mean)) +
geom_density(aes(fill=Gender_mean), alpha=0.3)
p3 <- ggplot(density_data.ALS, aes(x=Calcium_median, group = Gender_mean)) +
geom_density(aes(fill=Gender_mean), alpha=0.3)
p4 <- ggplot(density_data.ALS, aes(x=Sodium_median, group = Gender_mean)) +
geom_density(aes(fill=Gender_mean), alpha=0.3)
grid.arrange(p1,p2,p3,p4,nrow=2)
par(mfrow=c(1,2))
ALS_Data_Short <- subset(ALS_Data, select=c("Age_mean", "ALSFRS_slope",
"ALSFRS_Total_max", "ALSFRS_Total_median", "ALSFRS_Total_range",
"Blood.Urea.Nitrogen..BUN._median", "Blood.Urea.Nitrogen..BUN._min",
"Blood.Urea.Nitrogen..BUN._range", "bp_diastolic_median", "bp_systolic_median",
"Calcium_median", "Chloride_median", "Creatinine_median", "Glucose_median",
"Hemoglobin_median", "leg_median", "leg_min", "leg_range", "mouth_median",
"onset_delta_mean", "onset_site_mean", "respiratory_median", "Sodium_median",
"trunk_max", "trunk_median"))
ALS_Data_Short_Scale <- as.data.frame(lapply(ALS_Data_Short, scale))
set.seed(2019)
kmean_cluster <- kmeans(ALS_Data_Short_Scale, 3)
sil_kmean = silhouette(kmean_cluster$cluster, dist(ALS_Data_Short_Scale))
summary(sil_kmean)
plot(sil_kmean)
par(mfrow=c(1, 1), mar=c(4, 4, 4, 2))
mycolors <- c(paste("yellow",rev(1:4),sep=""),
paste("violetred",rev(1:4),sep=""),
paste("springgreen",rev(1:4),sep=""),
paste("slategray",rev(1:4),sep=""),
paste("plum",rev(1:4),sep=""),
paste("orangered",rev(1:4),sep=""),
"mediumblue")
barplot(t(kmean_cluster$centers), beside = T,
xlab="cluster", ylab="value", col = mycolors)
barplot(t(kmean_cluster$centers[1]), beside = F, col="white", axes = F)
legend("right", inset = c(-0.05,0), ncol = 2,
legend=c("Age_mean", "ALSFRS_slope",
"ALSFRS_Total_max", "ALSFRS_Total_median", "ALSFRS_Total_range",
"Blood.Urea.Nitrogen..BUN._median", "Blood.Urea.Nitrogen..BUN._min",
"Blood.Urea.Nitrogen..BUN._range", "bp_diastolic_median", "bp_systolic_median",
"Calcium_median", "Chloride_median", "Creatinine_median", "Glucose_median",
"Hemoglobin_median", "leg_median", "leg_min", "leg_range", "mouth_median",
"onset_delta_mean", "onset_site_mean", "respiratory_median", "Sodium_median",
"trunk_max", "trunk_median"), fill = mycolors)
kpp_init = function(dat, K) {
x = as.matrix(dat)
n = nrow(x)
# Randomly choose a first center
centers = matrix(NA, nrow=K, ncol=ncol(x))
set.seed(123)
centers[1,] = as.matrix(x[sample(1:n, 1),])
for (k in 2:K) {
# Calculate dist^2 to closest center for each point
dists = matrix(NA, nrow=n, ncol=k-1)
for (j in 1:(k-1)) {
temp = sweep(x, 2, centers[j,], '-')
dists[,j] = rowSums(temp^2)
}
dists = rowMins(dists)
# Draw next center with probability proportional to dist^2
cumdists = cumsum(dists)
prop = runif(1, min=0, max=cumdists[n])
centers[k,] = as.matrix(x[min(which(cumdists > prop)),])
}
return(centers)
}
n_rows <- 21
mat = matrix(0,nrow = n_rows)
for (i in 2:n_rows){
set.seed(321)
clust_kpp = kmeans(ALS_Data_Short_Scale, kpp_init(ALS_Data_Short_Scale, i), iter.max=100, algorithm='Lloyd')
sil = silhouette(clust_kpp$cluster, dist(ALS_Data_Short_Scale))
mat[i] = mean(as.matrix(sil)[,3])
}
colnames(mat) <- c("Avg_Silhouette_Value")
ggplot(data.frame(k=2:n_rows,sil=mat[2:n_rows]),aes(x=k,y=sil))+
geom_line()+
scale_x_continuous(breaks = 2:n_rows)
k <- 3
set.seed(2019)
clust_kpp = kmeans(ALS_Data_Short_Scale, kpp_init(ALS_Data_Short_Scale, k), iter.max=200, algorithm="MacQueen")
sil_kmean.opt = silhouette(clust_kpp$cluster, dist(ALS_Data_Short_Scale))
summary(sil_kmean.opt)
plot(sil_kmean.opt)
pitch_sing = agnes(ALS_Data_Short_Scale, diss=FALSE, method='single')
pitch_comp = agnes(ALS_Data_Short_Scale, diss=FALSE, method='complete')
pitch_ward = agnes(ALS_Data_Short_Scale, diss=FALSE, method='ward')
sil_sing = silhouette(cutree(pitch_sing, k=3), dist(ALS_Data_Short_Scale))
sil_comp = silhouette(cutree(pitch_comp, k=3), dist(ALS_Data_Short_Scale))
sil_ward = silhouette(cutree(pitch_ward, k=3), dist(ALS_Data_Short_Scale))
plot(sil_sing)
plot(sil_comp)
plot(sil_ward)
set.seed(2019)
gmm_clust <- Mclust(ALS_Data_Short_Scale)
gmm_clust$modelName
plot(gmm_clust$BIC, legendArgs = list(x = "bottom", ncol = 2, cex = 1))
mod <- Mclust(ALS_Data_Short_Scale[,1:6])
plot(mod, what = "density")
plot(mod, what = "classification")
sil_gauss = silhouette(as.numeric(gmm_clust$classification), dist(ALS_Data_Short_Scale))
plot(sil_gauss)
mean(sil_kmean[,3])
mean(sil_kmean.opt[,3])
mean(sil_sing[,3])
mean(sil_comp[,3])
mean(sil_ward[,3])
mean(sil_gauss[,3])
sil_kmean
sum(sil_kmean[sil_kmean==1,1])
sum(sil_kmean[which(sil_kmean==1),1])
sum(sil_kmean[,1][which(sil_kmean==1)])
sum(sil_kmean[,1])
sum(sil_kmean[,1])[which(sil_kmean==1)]
sil_kmean[which(sil_kmean==1),1]
sil_kmean[which(sil_kmean==1)]
sum(sil_kmean[which(sil_kmean==1)])
sum(sil_kmean[,1][which(sil_kmean==1)])
sil_kmean[,1][which(sil_kmean==1)]
sil_kmean[which(sil_kmean==1)][,1]
sil_kmean[which(sil_kmean==1)]
sil_kmean[,1][[which(sil_kmean==1)]]
sil_kmean[,1][which(sil_kmean==1)]
class(sil_kmean)
sum(sil_kmean[,1])[which(sil_kmean==1)]
sil_kmean[,1]
data.frame(sil_kmean[,1])
data.frame(sil_kmean[,1][which(sil_kmean==1)])
sum(data.frame(sil_kmean[,1][which(sil_kmean==1)]))
sum(na.omit(data.frame(sil_kmean[,1][which(sil_kmean==1)])))
sum(na.omit(sil_kmean[,1])[which(sil_kmean==1)])
na.omit(sil_kmean[,1])[which(sil_kmean==1)])
na.omit(sil_kmean[,1][which(sil_kmean==1)])
sum(na.omit(unlist(sil_kmean[,1][which(sil_kmean==1)])))
sum(na.omit(unlist(sil_kmean[,1][which(sil_kmean==2)])))
sum(na.omit(data.frame(sil_kmean[,1][which(sil_kmean==2)])))
length(na.omit(unlist(sil_kmean[,1][which(sil_kmean==2)])))
length(na.omit(unlist(sil_kmean[,1][which(sil_kmean==1)])))
length(na.omit(unlist(sil_kmean[,1][which(sil_kmean==2)])))
length(na.omit(unlist(sil_kmean[,1][which(sil_kmean==1)])))
length(na.omit(unlist(sil_kmean[,1][which(sil_kmean==2)])))
length(na.omit(unlist(sil_kmean[,1][which(sil_kmean==3)])))
sil_gauss
length(na.omit(unlist(sil_gauss[,3][which(sil_gauss<0)])))
sil_gauss[,3][which(sil_gauss<0)]
sil_gauss[,3]
sil_gauss[,3][which(sil_gauss<0)]
unlist(sil_gauss[,3][which(sil_gauss<0)])
data.frame(sil_gauss[,3][which(sil_gauss<0)])
sil_gauss[,3]
a<-sil_gauss[,3]
a[which(a<0)]
rm(a)
sil_gauss[,3][which(sil_gauss[,3]<0)]
which(sil_gauss[,3]<0)
sil_gauss[,3][
sil_gauss[,3][which(sil_gauss[,3]<0)]
sil_gauss[,3][which(sil_gauss[,3]<0)]
sil_gauss[,3][which(sil_gauss[,3]<0)]
sil_gauss
which(sil_gauss[,3]<0)
which(sil_kmean[,3]<0)
sil_kmean[,3]
tbl <- data.frame(
Average = (c(mean(sil_kmean[,3]),mean(sil_kmean.opt[,3]),mean(sil_sing[,3]),
mean(sil_comp[,3]),mean(sil_ward[,3]),mean(sil_gauss[,3]))),
Misclassification = (c(length(which(sil_kmean[,3]<0)),length(which(sil_kmean.opt[,3]<0)),length(which(sil_sing[,3]<0)),
length(which(sil_comp[,3]<0)),length(which(sil_ward[,3]<0)),length(which(sil_gauss[,3]<0)))),
"1" = (c(length(na.omit(unlist(sil_kmean[,1][which(sil_kmean==1)]))),
length(na.omit(unlist(sil_kmean[,1][which(sil_kmean.opt==1)]))),
length(na.omit(unlist(sil_kmean[,1][which(sil_sing==1)]))),
length(na.omit(unlist(sil_kmean[,1][which(sil_comp==1)]))),
length(na.omit(unlist(sil_kmean[,1][which(sil_ward==1)]))),
length(na.omit(unlist(sil_kmean[,1][which(sil_gauss==1)]))))),
"2" = (c(length(na.omit(unlist(sil_kmean[,1][which(sil_kmean==2)]))),
length(na.omit(unlist(sil_kmean[,1][which(sil_kmean.opt==2)]))),
length(na.omit(unlist(sil_kmean[,1][which(sil_sing==2)]))),
length(na.omit(unlist(sil_kmean[,1][which(sil_comp==2)]))),
length(na.omit(unlist(sil_kmean[,1][which(sil_ward==2)]))),
length(na.omit(unlist(sil_kmean[,1][which(sil_gauss==2)]))))),
"3" = (c(length(na.omit(unlist(sil_kmean[,1][which(sil_kmean==3)]))),
length(na.omit(unlist(sil_kmean[,1][which(sil_kmean.opt==3)]))),
length(na.omit(unlist(sil_kmean[,1][which(sil_sing==3)]))),
length(na.omit(unlist(sil_kmean[,1][which(sil_comp==3)]))),
length(na.omit(unlist(sil_kmean[,1][which(sil_ward==3)]))),
length(na.omit(unlist(sil_kmean[,1][which(sil_gauss==3)])))))
)
View(tbl)
tbl <- data.frame(Method = c("K-Means", "K-Means (Optimized)", "Single linkage", "Complete linkage", "Mean linkage", "GMM"),
Average = (c(mean(sil_kmean[,3]),mean(sil_kmean.opt[,3]),mean(sil_sing[,3]),
mean(sil_comp[,3]),mean(sil_ward[,3]),mean(sil_gauss[,3]))),
Misclassification = (c(length(which(sil_kmean[,3]<0)),length(which(sil_kmean.opt[,3]<0)),length(which(sil_sing[,3]<0)),
length(which(sil_comp[,3]<0)),length(which(sil_ward[,3]<0)),length(which(sil_gauss[,3]<0)))),
"1" = (c(length(na.omit(unlist(sil_kmean[,1][which(sil_kmean==1)]))),
length(na.omit(unlist(sil_kmean[,1][which(sil_kmean.opt==1)]))),
length(na.omit(unlist(sil_kmean[,1][which(sil_sing==1)]))),
length(na.omit(unlist(sil_kmean[,1][which(sil_comp==1)]))),
length(na.omit(unlist(sil_kmean[,1][which(sil_ward==1)]))),
length(na.omit(unlist(sil_kmean[,1][which(sil_gauss==1)]))))),
"2" = (c(length(na.omit(unlist(sil_kmean[,1][which(sil_kmean==2)]))),
length(na.omit(unlist(sil_kmean[,1][which(sil_kmean.opt==2)]))),
length(na.omit(unlist(sil_kmean[,1][which(sil_sing==2)]))),
length(na.omit(unlist(sil_kmean[,1][which(sil_comp==2)]))),
length(na.omit(unlist(sil_kmean[,1][which(sil_ward==2)]))),
length(na.omit(unlist(sil_kmean[,1][which(sil_gauss==2)]))))),
"3" = (c(length(na.omit(unlist(sil_kmean[,1][which(sil_kmean==3)]))),
length(na.omit(unlist(sil_kmean[,1][which(sil_kmean.opt==3)]))),
length(na.omit(unlist(sil_kmean[,1][which(sil_sing==3)]))),
length(na.omit(unlist(sil_kmean[,1][which(sil_comp==3)]))),
length(na.omit(unlist(sil_kmean[,1][which(sil_ward==3)]))),
length(na.omit(unlist(sil_kmean[,1][which(sil_gauss==3)])))))
)
View(tbl)
library(crossval)
ppmi_data <-read.csv("https://umich.instructure.com/files/330400/download?download_frd=1",header=TRUE)
View(ppmi_data)
library(neuralnet)
set.seed(1234)
Power <- function(lambda)
{
if(lambda>=1){
M=0
N=1
}else if(lambda<=-1){
M=0.3
N=1
}else if(lambda>0){
M=0
N=10
}else{
M=0.3
N=10
}
# generate random training data
rand_data <- runif(1000, M,N)
power_df <- data.frame(rand_data, power_data=(rand_data^lambda))
# Train the neural net
net.power <- neuralnet(power_data ~ rand_data,  power_df, hidden=10, threshold=0.1)
# report the NN
# generate testing data seq
test_data <- seq(M, N, (N-M)/2000); test_data_power <-(test_data^lambda)
test_data.df <- data.frame(rand_data=test_data, power_data=(test_data^lambda));
# try to predict the power values using 10 hidden nodes
# Compute or predict for test data input, test_data.df
pred_power <- predict(net.power, test_data.df)
# compute uses the trained neural net (net.power),
# to estimate the power of the testing data
# compare real (test_data_power) and NN-predicted (pred_power) power of test_data
plot(pred_power, test_data_power);
abline(0,1, col="red", lty=2)
legend("bottomright",  c("Pred vs. Actual POWER", "Pred=Actual Line"), cex=0.8, lty=c(1,2),
lwd=c(2,2),col=c("black","red"))
compare_df <-data.frame(pred_power, test_data_power); # compare_df
plot(test_data, test_data_power)
lines(test_data, pred_power, pch=22, col="red", lty=2)
legend("bottomright",  c("Actual POWER","Predicted POWER"),
lty=c(1,2),lwd=c(2,2),col=c("black","red"))
}
#given lambda=3
Power(3)
#given lambda=3
Power(1)
library('neuralnet')
random = runif(1000, 0, 20)
lambda = 20
third_power = data.frame(random, data = random^(lambda))
plot(random, third_power$data)
net.sqrt = neuralnet(data ~ random, third_power, hidden = c(10, 5, 3), threshold = 0.2)
knitr::opts_chunk$set(echo = TRUE)
library("neuralnet")
library("cluster")
library("matrixStats")
library("ggplot2")
library("ggdendro")
library("neuralnet")
library("cluster")
library("matrixStats")
library("ggplot2")
# library("ggdendro")
# library("mclust")
lambda = -20
ramdomD = runif(2000, 0, 1)
dfPower = data.frame(ramdomD,powerD=(ramdomD^lambda))
net.power = neuralnet(powerD ~ ramdomD, dfPower, hidden=10, threshold=0.01)
testD = seq(0, 1, 1/2000)
testDPower = (testD ^lambda)
testD.df = data.frame(ramdomD=testD , powerD=testD^lambda);
prePower = predict(net.power, testD.df)
shiny::runGist('3239667')
load("jel_data.Rda")
jel_data_keywords <- Corpus(VectorSource(jel_data$Keywords))
library(jsonlite); library(rvest); library(tm); library(SnowballC); library(cld2);library(httr);library(XML)
library(V8); library(dplyr); library(DT); library(stringi)
load("jel_data.Rda")
jel_data_keywords <- Corpus(VectorSource(jel_data$Keywords))
jel_data_keywords <- tm_map(jel_data_keywords, tolower)
jel_data_keywords <- tm_map(jel_data_keywords, removePunctuation)
jel_data_keywords <- tm_map(jel_data_keywords, removeNumbers)
jel_data_keywords <- tm_map(jel_data_keywords, removeWords, stopwords("english"))
jel_data_keywords <- tm_map(jel_data_keywords, stripWhitespace)
jel_data <- load("https://github.com/steroidfella/HS650F2019/blob/master/Data/jel_data.Rda")
library(jsonlite); library(rvest); library(tm); library(SnowballC); library(cld2);library(httr);library(XML)
library(V8); library(dplyr); library(DT); library(stringi); library(repmis)
library(jsonlite); library(rvest); library(tm); library(SnowballC); library(cld2);library(httr);library(XML)
library(V8); library(dplyr); library(DT); library(stringi); install.packages(repmis)
library(V8); library(dplyr); library(DT); library(stringi); install.packages("repmis")
library(jsonlite); library(rvest); library(tm); library(SnowballC); library(cld2);library(httr);library(XML)
library(V8); library(dplyr); library(DT); library(stringi); library("repmis")
jel_data <- source_data("https://github.com/steroidfella/HS650F2019/blob/master/Data/jel_data.Rda")
library(jsonlite); library(rvest); library(tm); library(SnowballC); library(cld2);library(httr);library(XML)
library(V8); library(dplyr); library(DT); library(stringi); library("repmis")
library(jsonlite); library(rvest); library(tm); library(SnowballC); library(cld2);library(httr);library(XML)
library(V8); library(dplyr); library(DT); library(stringi); library(repmis)
jel_data <- source_data("https://github.com/steroidfella/HS650F2019/blob/master/Data/jel_data.Rda")
jel_data <- source_data("https://github.com/steroidfella/HS650F2019/blob/master/Data/jel_data.Rda")
jel_data <- source_data("https://github.com/steroidfella/HS650F2019/blob/master/Data/jel_data.Rda?raw=true")
source_data("https://github.com/steroidfella/HS650F2019/blob/master/Data/jel_data.Rda?raw=true")
source_data("https://github.com/steroidfella/HS650F2019/blob/master/Data/jel_data.Rda?raw=true")
source_data("https://github.com/steroidfella/HS650F2019/blob/master/Data/jel_data.Rda?raw=true")
str(jel_data)
?source_data
temodir
tempdir
?tempdir
tempdir(check = T)
source_data("https://github.com/steroidfella/HS650F2019/blob/master/Data/jel_data.Rda?raw=true", clearCache = T)
library(jsonlite); library(rvest); library(tm); library(SnowballC); library(cld2);library(httr);library(XML)
library(V8); library(dplyr); library(DT); library(stringi); library(repmis)
source_data("https://github.com/steroidfella/HS650F2019/blob/master/Data/jel_data.Rda?raw=true", clearCache = T)
str(jel_data)
jel_data_keywords <- Corpus(VectorSource(jel_data$Keywords))
jel_data_keywords <- tm_map(jel_data_keywords, tolower)
jel_data_keywords <- tm_map(jel_data_keywords, removePunctuation)
jel_data_keywords <- tm_map(jel_data_keywords, removeNumbers)
jel_data_keywords <- tm_map(jel_data_keywords, removeWords, stopwords("english"))
jel_data_keywords <- tm_map(jel_data_keywords, stripWhitespace)
keywords_clean <- matrix(0, nrow = nrow(jel_data), ncol = 1)
for (i in 1:nrow(jel_data)){
keywords_clean[i] <- as.character(jel_data_keywords[[i]])
}
jel_data <- cbind(jel_data, keywords_clean)
jel_data$keywords_clean <- as.character(jel_data$keywords_clean)
rm(keywords_clean)
datatable(head(jel_data))
datatable(head(jel_data))
C:/Users/Nadhil/Google Drive/Umich/!!Course Material/Fall 2019/HS 650/Term Paper/FlowChart.jpg
FlowChart.jpg
(C:/Users/Nadhil/Google Drive/Umich/!!Course Material/Fall 2019/HS 650/Term Paper/FlowChart.jpg)
include_graphics("C:/Users/Nadhil/Google Drive/Umich/!!Course Material/Fall 2019/HS 650/Term Paper/FlowChart.jpg")
"C:/Users/Nadhil/Google Drive/Umich/!!Course Material/Fall 2019/HS 650/Term Paper/FlowChart.jpg"
![dog pict](C:/Users/Nadhil/Google Drive/Umich/!!Course Material/Fall 2019/HS 650/Term Paper/FlowChart.jpg)
library(tibble);library(kableExtra);library(rvest);library(knitr)
library(jsonlite); library(rvest); library(tm); library(SnowballC); library(cld2);library(httr);library(XML)
library(V8); library(dplyr); library(DT); library(stringi); library(repmis)
include_graphics("https://github.com/steroidfella/HS650F2019/blob/master/Data/FlowChart.jpg")
include_graphics("C:\Users\Nadhil\Google Drive\Umich\!!Course Material\Fall 2019\HS 650\Term Paper\FlowChart.jpg")
include_graphics("C:/Users/Nadhil/Google Drive/Umich/!!Course Material/Fall 2019/HS 650/Term Paper/FlowChart.jpg")
shiny::runApp('C:/Users/Nadhil/Dropbox/Umich/!!Course Material/Fall 2018/SurvMeth 727/Assignment/Excercise 6/NewRow')
install.package("shinythemes")
install.package("shinythemes")
install.package("shinythemes")
install.package("shinythemes")
install.packages("shinythemes")
runApp('C:/Users/Nadhil/Dropbox/Umich/!!Course Material/Fall 2018/SurvMeth 727/Assignment/Excercise 6/NewRow')
load(term_data.RData)
load(term_data.RData)
load("term_data.RData")
View(epubs_json_short)
runApp('C:/Users/Nadhil/Dropbox/Umich/!!Course Material/Fall 2018/SurvMeth 727/Assignment/Excercise 6/NewRow')
install.packages("shiny")
install.packages("shiny")
install.packages("shiny")
install.packages("shiny")
install.packages("shiny")
shiny::runApp('C:/Users/Nadhil/Dropbox/Umich/!!Course Material/Fall 2018/SurvMeth 727/Assignment/Excercise 6/NewRow')
library("htmltools", lib.loc="C:/Program Files/R/R-3.6.1/library")
install.packages("htmltools")
library("htmltools", lib.loc="C:/Program Files/R/R-3.6.1/library")
detach("package:htmltools", unload=TRUE)
install.packages("htmltools")
setwd
setwd()
getwd()
shiny::runApp('C:/Users/Nadhil/Dropbox/Umich/!!Course Material/Fall 2018/SurvMeth 727/Assignment/Excercise 6/NewRow')
install.packages("htmltools")
shiny::runApp('C:/Users/Nadhil/Dropbox/Umich/!!Course Material/Fall 2018/SurvMeth 727/Assignment/Excercise 6/NewRow')
runApp('C:/Users/Nadhil/Dropbox/Umich/!!Course Material/Fall 2018/SurvMeth 727/Assignment/Excercise 6/NewRow')
runApp('C:/Users/Nadhil/Dropbox/Umich/!!Course Material/Fall 2018/SurvMeth 727/Assignment/Excercise 6/NewRow')
syop
stop
shiny::runGitHub("HS650F2019","steroidfella")
shiny::runGitHub("HS650F2019","steroidfella")
shiny::runGitHub("HS650F2019","steroidfella")
shiny::runGitHub("HS650F2019","steroidfella")
shiny::runApp('GitHub/HS650')
runApp('GitHub/HS650')
